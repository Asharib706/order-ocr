import os
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")

supabase: Client = None

if url and key and "your_supabase" not in url:
    try:
        supabase = create_client(url, key)
    except Exception as e:
        print(f"Failed to initialize Supabase client: {e}")

def get_supabase_client():
    return supabase

def insert_work_orders(data_list):
    """
    Inserts a list of work order dictionaries into Supabase.
    """
    if not supabase:
        return {"error": "Supabase not configured"}
    
    try:
        # data_list contains dicts. data_list needs to match the table entries.
        # We need to filter keys that are not in the table if strict, but Supabase/Postgrest usually ignores extra if configured? 
        # Actually usually it errors on unknown columns.
        # Let's ensure we only send known columns.
        valid_keys = {'work_order_number', 'job_number', 'description', 'hours', 'date', 'total_amount_due', 'signed_by_both', 'customer_sign', 'wcdp_sign', 'raw_text'}
        
        cleaned_data = []
        for item in data_list:
            clean_item = {k: v for k, v in item.items() if k in valid_keys}
            cleaned_data.append(clean_item)

        response = supabase.table("work_orders").insert(cleaned_data).execute()
        return response
    except Exception as e:
        return {"error": str(e)}

FRAMEWORK_DB_SCHEMA = """
-- Run this in your Supabase SQL Editor
create table public.work_orders (
  id bigint generated by default as identity,
  created_at timestamp with time zone not null default now(),
  work_order_number text,
  job_number text,
  description text,
  hours text,
  date text,
  total_amount_due text,
  signed_by_both boolean,
  customer_sign boolean,
  wcdp_sign boolean,
  raw_text text,
  constraint work_orders_pkey primary key (id)
);
"""

def fetch_work_orders(page=1, page_size=10, search_query="", filters=None, sort_by="created_at", ascending=False):
    """
    Fetches work orders from Supabase with pagination, search, filters, and sorting.
    filters: dict with keys like 'hours', 'signed_by_both', 'customer_sign', 'wcdp_sign'
    """
    if not supabase:
        return {"error": "Supabase not configured", "data": [], "count": 0}
    
    try:
        query = supabase.table("work_orders").select("*", count="exact")
        
        # Search
        if search_query:
            f = f"work_order_number.ilike.%{search_query}%,job_number.ilike.%{search_query}%,description.ilike.%{search_query}%"
            query = query.or_(f)
            
        # Filters
        if filters:
            if filters.get("hours"):
                query = query.eq("hours", filters["hours"])
            
            # Boolean filters (expecting True/False, ignore if None)
            for bool_col in ["signed_by_both", "customer_sign", "wcdp_sign"]:
                val = filters.get(bool_col)
                if val is not None:
                     query = query.eq(bool_col, val)

        # Sorting
        query = query.order(sort_by, desc=not ascending)

        # Pagination
        start = (page - 1) * page_size
        end = start + page_size - 1
        query = query.range(start, end)
        
        response = query.execute()
        return {"data": response.data, "count": response.count}
        
    except Exception as e:
        return {"error": str(e), "data": [], "count": 0}

def fetch_all_work_orders(search_query="", filters=None, sort_by="created_at", ascending=False):
    """
    Fetches all matching work orders for export.
    """
    if not supabase:
        return []
    
    try:
        query = supabase.table("work_orders").select("*")
        
        # Search
        if search_query:
            f = f"work_order_number.ilike.%{search_query}%,job_number.ilike.%{search_query}%,description.ilike.%{search_query}%"
            query = query.or_(f)
            
        # Filters
        if filters:
            if filters.get("hours"):
                query = query.eq("hours", filters["hours"])
            
            for bool_col in ["signed_by_both", "customer_sign", "wcdp_sign"]:
                val = filters.get(bool_col)
                if val is not None:
                     query = query.eq(bool_col, val)
            
        # Sorting
        query = query.order(sort_by, desc=not ascending)
        
        response = query.execute()
        return response.data
        
    except Exception as e:
        print(f"Error fetching all data: {e}")
        return []

def fetch_distinct_hours():
    """Fetches unique values for the 'hours' column."""
    if not supabase:
        return []
    try:
        # Currently Supabase-py doesn't strictly support distinct() in a simple way 
        # without a hack or calling a generic function. 
        # But we can select just the column and process in python if small, 
        # or use .select('hours').limit(1000) and set() it.
        # Efficient way: .select('hours') -> distinct in python (easiest for small datasets)
        
        response = supabase.table("work_orders").select("hours").execute()
        if response.data:
            hours = {r['hours'] for r in response.data if r['hours']}
            return sorted(list(hours))
        return []
    except Exception as e:
        return []
